{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xmMV3zELKiJg"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "newsgroups = fetch_20newsgroups(remove=('headers', 'footers', 'quotes'))\n",
        "\n",
        "all_df = pd.DataFrame({'Text': newsgroups.data, 'Category Label': newsgroups.target})\n",
        "all_df['Category Name'] = all_df['Category Label'].map(lambda idx: newsgroups.target_names[idx]);\n",
        "#print(all_df['Category Name'].value_counts())\n",
        "#print(all_df['Text'][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FXL3AIOoKiJh"
      },
      "outputs": [],
      "source": [
        "New_DF = all_df.loc[all_df['Category Name'] == 'sci.space']\n",
        "New_DF = New_DF.append(all_df.loc[all_df['Category Name'] == 'sci.med'])\n",
        "New_DF = New_DF .append(all_df.loc[all_df['Category Name'] =='comp.graphics'])\n",
        "\n",
        "#Train = New_DF.sample(frac = 0.7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VBQr0lY_SaEd"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1P_zXwVqKiJh"
      },
      "outputs": [],
      "source": [
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(New_DF['Text'])\n",
        "print('tf_idf Ten most important words: \\n', sorted(list(zip(vectorizer.get_feature_names_out(), X.sum(0).getA1())), \n",
        "                                 key=lambda x: x[1], reverse=True)[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tURlYlRDKiJi"
      },
      "outputs": [],
      "source": [
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "X = vectorizer.fit_transform(New_DF['Text'])\n",
        "print('tf_idf Ten most important words: \\n', sorted(list(zip(vectorizer.get_feature_names_out(), X.sum(0).getA1())), \n",
        "                                 key=lambda x: x[1], reverse=True)[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T1d3NI8fKiJi"
      },
      "outputs": [],
      "source": [
        "vectorizer =TfidfVectorizer(stop_words='english')\n",
        "X = vectorizer.fit_transform(New_DF['Text'])\n",
        "pca = PCA(n_components=2)\n",
        "PCA_X = pca.fit_transform(X.toarray())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b6G6n_9zVxEO"
      },
      "outputs": [],
      "source": [
        "x0 = PCA_X[:, 0]\n",
        "x1 = PCA_X[:, 1]\n",
        "PCADF = New_DF.copy()\n",
        "PCADF['x0'] = x0\n",
        "PCADF [\"x1\"]= x1\n",
        "GRAPH = PCADF.loc[PCADF['Category Name'] == 'sci.space']\n",
        "GRAPH2 =PCADF.loc[PCADF['Category Name'] == 'sci.med']\n",
        "GRAPH3 = PCADF.loc[PCADF['Category Name'] == 'comp.graphics']\n",
        "fig ,ax= plt.subplots(1)\n",
        "ax.scatter(GRAPH['x0'],GRAPH['x1'], c='red', label ='sci.space' )\n",
        "ax.scatter(GRAPH2['x0'],GRAPH2['x1'], c='green', label ='sci.med')\n",
        "ax.scatter(GRAPH3['x0'],GRAPH3['x1'], c='blue', label ='comp.graphics' )\n",
        "ax.legend()\n",
        "fig.set_size_inches(15,15)\n",
        "plt.xlim(-.055, .021)\n",
        "plt.title(\"PCA Visualization\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iRDfAMTidwJy"
      },
      "outputs": [],
      "source": [
        "vectorizer =TfidfVectorizer(stop_words='english')\n",
        "X = vectorizer.fit_transform(New_DF['Text'])\n",
        "tsne = TSNE()\n",
        "TSNE_X= tsne.fit_transform(X.toarray());"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "341P3jpXKiJi"
      },
      "outputs": [],
      "source": [
        "x5 = TSNE_X[:, 0]\n",
        "x6 = TSNE_X[:, 1]\n",
        "TSNE= New_DF.copy()\n",
        "TSNE['x0'] = x5\n",
        "TSNE[\"x1\"]= x6\n",
        "GRAPH4 = TSNE.loc[TSNE['Category Name'] == 'sci.space']\n",
        "GRAPH5 =TSNE.loc[TSNE['Category Name'] == 'sci.med']\n",
        "GRAPH6 = TSNE.loc[TSNE['Category Name'] == 'comp.graphics']\n",
        "colors = {'sci.space':'red', 'sci.med':'green', 'comp.graphics':'blue'}\n",
        "fig , ax= plt.subplots(1)\n",
        "ax.scatter(GRAPH4['x0'],GRAPH4['x1'], c='red', label ='sci.space' )\n",
        "ax.scatter(GRAPH5['x0'],GRAPH5['x1'], c='green', label ='sci.med')\n",
        "ax.scatter(GRAPH6['x0'],GRAPH6['x1'], c='blue', label ='comp.graphics' )\n",
        "ax.legend()\n",
        "fig.set_size_inches(15,15)\n",
        "plt.title(\"TSNE Visualization\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KqVVxKM5KiJi"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "vectorizer =TfidfVectorizer(stop_words='english')\n",
        "X = vectorizer.fit_transform(New_DF['Text'])\n",
        "kmeans = KMeans(n_clusters = 5)\n",
        "kmeans.fit(X)\n",
        "clusters = kmeans.labels_\n",
        "ClusterCenters = kmeans.cluster_centers_\n",
        "PCADF[\"clusters\"] = clusters\n",
        "\n",
        "CCNew=pca.transform(ClusterCenters)\n",
        "x2 = CCNew[:, 0]\n",
        "x3 = CCNew[:, 1]\n",
        "clus = (1,2,3,4,5)\n",
        "### find distance between points and cluster centers\n",
        "for y in range(0,5):\n",
        "  PCADF['x0Squared'] = (PCADF['x0']-x2[y]).pow(2)\n",
        "  PCADF [\"x1Squeared\"]= (PCADF['x1']-x3[y]).pow(2)\n",
        "  PCADF[\"Temp\"] = PCADF [\"x1Squeared\"]+ PCADF['x0Squared']\n",
        "  PCADF[\"Temp2\"] = PCADF[\"Temp\"]**(1/2)\n",
        "  PCADF[str(clus[y])] = PCADF[\"Temp2\"] \n",
        "\n",
        "PCADF [\"PointDistance\"] = PCADF['x0Squared']  + PCADF [\"x1Squeared\"]\n",
        "\n",
        "\n",
        "Xpoints = []\n",
        "Ypoints = []\n",
        "for b in range(0, 5):\n",
        "  Tempor_DF = PCADF.sort_values(str(clus[b]))\n",
        "  for z in range(0,5):\n",
        "    print(\"Cluster\" ,b,':(', Tempor_DF['x0'].iat[z],Tempor_DF['x1'].iat[z],\")\" )\n",
        "    Xpoints.append(Tempor_DF['x0'].iat[z])\n",
        "    Ypoints.append(Tempor_DF['x1'].iat[z])\n",
        "\n",
        "GRAPH7 = PCADF.loc[PCADF['clusters'] == 0]\n",
        "GRAPH8 =PCADF.loc[PCADF['clusters'] == 1]\n",
        "GRAPH9 =PCADF.loc[PCADF['clusters'] == 2]\n",
        "GRAPH10 =PCADF.loc[PCADF['clusters'] == 3]\n",
        "GRAPH11 = PCADF.loc[PCADF['clusters'] == 4]\n",
        "\n",
        "fig, ax = plt.subplots(1)\n",
        "ax.set_title('PCA (KMeans)')\n",
        "fig.set_size_inches(15,15)\n",
        "ax.scatter(GRAPH7['x0'],GRAPH7['x1'], c='red', label ='Cluster 1' )\n",
        "ax.scatter(GRAPH8['x0'],GRAPH8['x1'], c='green', label ='Cluster 2')\n",
        "ax.scatter(GRAPH9['x0'],GRAPH9['x1'], c='blue', label ='Cluster 3' )\n",
        "ax.scatter(GRAPH10['x0'],GRAPH10['x1'], c='yellow', label ='Cluster 4')\n",
        "ax.scatter(GRAPH11['x0'],GRAPH11['x1'], c='orange', label ='Cluster 5' )\n",
        "ax.scatter(Xpoints,Ypoints,color = 'grey', marker = \"X\", label ='Five Closest Points')\n",
        "ax.scatter(x2,x3,color = 'black', marker = \"X\", label ='Cluster Centers')\n",
        "ax.legend()\n",
        "plt.xlim(-.055, .75)\n",
        "plt.ylim(-.3, .3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DQKqvFKeKiJi"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from scipy.cluster.hierarchy import dendrogram\n",
        "Aggo = AgglomerativeClustering(distance_threshold=0, n_clusters=None)\n",
        "Aggo.fit(X.toarray());"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hWe9uJgAYo1b"
      },
      "outputs": [],
      "source": [
        "###\n",
        "#SOURCE (https://scikit-learn.org/stable/auto_examples/cluster/plot_agglomerative_dendrogram.html)#\n",
        "###\n",
        "def plot_dendrogram(model, **kwargs):\n",
        "    # Create linkage matrix and then plot the dendrogram\n",
        "\n",
        "    # create the counts of samples under each node\n",
        "    counts = np.zeros(model.children_.shape[0])\n",
        "    n_samples = len(model.labels_)\n",
        "    for i, merge in enumerate(model.children_):\n",
        "        current_count = 0\n",
        "        for child_idx in merge:\n",
        "            if child_idx < n_samples:\n",
        "                current_count += 1  # leaf node\n",
        "            else:\n",
        "                current_count += counts[child_idx - n_samples]\n",
        "        counts[i] = current_count\n",
        "\n",
        "    linkage_matrix = np.column_stack(\n",
        "        [model.children_, model.distances_, counts]\n",
        "    ).astype(float)\n",
        "\n",
        "    # Plot the corresponding dendrogram\n",
        "    dendrogram(linkage_matrix, **kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S21--GE_XKyw"
      },
      "outputs": [],
      "source": [
        "from scipy.cluster.hierarchy import linkage\n",
        "plt.figure(figsize=(14, 9))\n",
        "plot_dendrogram(Aggo, truncate_mode=\"level\", p=3)\n",
        "plt.title(\"Agglomerative Clustering Dendrogram\")\n",
        "plt.xlabel(\"Number of points in node (or index of point if no parenthesis).\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQIO8yRGKiJi"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "vectorizer =TfidfVectorizer(stop_words='english')\n",
        "X = vectorizer.fit_transform(New_DF['Text'])\n",
        "dbscan = DBSCAN(eps=.00001, min_samples=2,  leaf_size=90)\n",
        "dbscan.fit(X)\n",
        "cluster = dbscan.labels_\n",
        "PCADF[\"DBSCAN Clusters\"] = cluster\n",
        "print(PCADF[\"DBSCAN Clusters\"].unique())\n",
        "\n",
        "GRAPH12 = PCADF.loc[PCADF['DBSCAN Clusters'] == 0]\n",
        "GRAPH13 =PCADF.loc[PCADF['DBSCAN Clusters'] == 1]\n",
        "GRAPH14 =PCADF.loc[PCADF['DBSCAN Clusters'] == 2]\n",
        "GRAPH15 =PCADF.loc[PCADF['DBSCAN Clusters'] == 3]\n",
        "GRAPH16 = PCADF.loc[PCADF['DBSCAN Clusters'] == 4]\n",
        "GRAPH17 = PCADF.loc[PCADF['DBSCAN Clusters'] == -1]\n",
        "\n",
        "fig, ax = plt.subplots(1)\n",
        "ax.set_title('PCA (DBSCAN Clustering)')\n",
        "fig.set_size_inches(15,15)\n",
        "ax.scatter(GRAPH17['x0'],GRAPH17['x1'], c='orange', label ='Cluster 6' )\n",
        "ax.scatter(GRAPH12['x0'],GRAPH12['x1'], c='red', label ='Cluster 1' )\n",
        "ax.scatter(GRAPH13['x0'],GRAPH13['x1'], c='green', label ='Cluster 2')\n",
        "ax.scatter(GRAPH14['x0'],GRAPH14['x1'], c='blue', label ='Cluster 3' )\n",
        "ax.scatter(GRAPH15['x0'],GRAPH15['x1'], c='yellow', label ='Cluster 4')\n",
        "ax.scatter(GRAPH16['x0'],GRAPH16['x1'], c='purple', label ='Cluster 5' )\n",
        "ax.legend()\n",
        "plt.xlim(-.055, .75)\n",
        "plt.ylim(-.3, .3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gDr6Sj1Ovum2"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import RidgeClassifier\n",
        "from sklearn import svm\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from matplotlib import pyplot\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8xIOSDFGgHGB"
      },
      "outputs": [],
      "source": [
        "#split the data first\n",
        "X_train, X_test, y_train, y_test = train_test_split(New_DF['Text'], New_DF['Category Label'], test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0eq0PbHXKiJi"
      },
      "outputs": [],
      "source": [
        "classifier =  Pipeline([(\"TfidfVectorizer\" ,TfidfVectorizer(stop_words='english')),(\"model\",SGDClassifier())])\n",
        "classifier.fit(X_train, y_train) \n",
        "y_pred = classifier.predict(X_test)\n",
        "print(\"SGDClassifier\" , ' : ' , classifier.score(X_test, y_test))\n",
        "TempDF = pd.DataFrame()\n",
        "TempDF['FeatureNames'] = classifier[0].get_feature_names_out()\n",
        "Coef = classifier[1].coef_\n",
        "for p in range(0,len(Coef)):\n",
        "  TempDF[str(p)] = Coef[p]\n",
        "\n",
        "for d in range(0,len(Coef)):\n",
        "  Newm = TempDF.sort_values(str(d), ascending = False).copy()\n",
        "  print(d, \" vs rest ten most important words: \", end=\" \")\n",
        "  for z in range(0,10):\n",
        "    print('[','#',z+1, \"|\",Newm['FeatureNames'].iat[z], \"|\",\" Coef: \",Newm[str(d)].iat[z] ,']' ,end=\" \")\n",
        "  print('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AA5Hmryfq42i"
      },
      "outputs": [],
      "source": [
        "\n",
        "ParamGrid = [ {'model__alpha': np.linspace(0.5, 1.5, 6)},                   \n",
        "                              {'model__alpha': np.linspace(0.5, 1.5, 6),\n",
        "                                'model__fit_prior': [True, False]}]\n",
        "models = [RidgeClassifier(),  MultinomialNB()]\n",
        "Temp2DF = pd.DataFrame()\n",
        "for  z in range(0,len(models)):\n",
        "  temp = Pipeline([(\"TfidfVectorizer\" ,TfidfVectorizer(stop_words='english')),(\"model\",models[z])])\n",
        "  temp2 = temp.fit(X_train, y_train)\n",
        "  print(str(models[z]) , ' : ' , temp2.score(X_test,y_test))\n",
        "  Gridtemp = GridSearchCV(temp, param_grid=ParamGrid[z],cv = 5)\n",
        "  Gridtemp.fit(X_train, y_train)\n",
        "  print(str(models[z]) , ' : ' , Gridtemp.score(X_test,y_test))\n",
        "  print(str(models[z]) , \"Best Parameters:\" , Gridtemp.best_params_)\n",
        "  Coef = temp[1].coef_\n",
        "  Temp2DF['FeatureNames'] = classifier[0].get_feature_names_out()\n",
        "  for p in range(0,len(Coef)):\n",
        "    Temp2DF[str(p)] = Coef[p]\n",
        "\n",
        "  for d in range(0,len(Coef)):\n",
        "    Newm = Temp2DF.sort_values(str(d), ascending = False).copy()\n",
        "    print(d, \" vs rest ten most important words: \", end=\" \")\n",
        "    for z in range(0,10):\n",
        "      print('[','#',z+1, \"|\",Newm['FeatureNames'].iat[z], \"|\",\" Coef: \",Newm[str(d)].iat[z] ,']' ,end=\" \")\n",
        "    print('\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fvP1F0-LtNac"
      },
      "outputs": [],
      "source": [
        "Temp3DF = pd.DataFrame()\n",
        "Temp4DF = pd.DataFrame()\n",
        "ParamGrid = [ { \"model__n_estimators\" : [90,100,115,1000], \n",
        "                                'model__criterion': ['gini', 'entropy'],\n",
        "                                  'model__max_depth' : range(5,10), \n",
        "                                 'model__max_features' : ['auto','log2'] },\n",
        "                             {  'model__criterion': ['gini', 'entropy']}]\n",
        "models = [RandomForestClassifier(),  DecisionTreeClassifier()]\n",
        "for  z in range(0,len(models)):\n",
        "  temp = Pipeline([(\"TfidfVectorizer\" ,TfidfVectorizer(stop_words='english')),(\"model\",models[z])])\n",
        "  temp2 = temp.fit(X_train, y_train)\n",
        "  print(str(models[z]) , ' : ' , temp2.score(X_test,y_test))\n",
        "  Gridtemp = GridSearchCV(temp, param_grid=ParamGrid[z],cv = 5)\n",
        "  Gridtemp.fit(X_train, y_train)\n",
        "  print(str(models[z]) , ' : ' , Gridtemp.score(X_test,y_test))\n",
        "  print(str(models[z]) , \"Best Parameters:\" , Gridtemp.best_params_)\n",
        "  Temp3DF['FeatureNames'] = classifier[0].get_feature_names_out()\n",
        "  Temp4DF['FeatureNames'] = classifier[0].get_feature_names_out()\n",
        "  Temp3DF[\"Coef\"]  = temp[1].feature_importances_\n",
        "  Newm = Temp3DF.sort_values('Coef', ascending = False).copy()\n",
        "  print(\"Top ten words:\", end=\" \")\n",
        "  for h in range(0,10):\n",
        "    print('[','#',h+1, \"|\",Newm['FeatureNames'].iat[h], \"|\",\" Coeff: \",Newm[\"Coef\"].iat[h] ,']' ,end=\" \")\n",
        "  print('\\n')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
